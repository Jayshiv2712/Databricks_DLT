bundle:
  name: dlt-apply-changes-from-snapshot-demo
  version: 0.0.1
  description: DLT Apply Changes from Snapshot Demo

variables:
# required for pattern 2
  my_instance_profile_arn:
    description: The IAM role to access S3 bucket.
    default: ""
  # required for pattern 2
  my_s3_bucket:
    description: The S3 bucket to store the snapshots.
    default: "dbfs:/demo"
  num_orders:
    description: The number of orders to generate.
    default: "10"

resources:
  pipelines:
    dlt_snapshot_ingestion_pattern1:
      name: "DLT Apply Changes from Snapshot - Pattern1 [${workspace.current_user.id}]"
      target: "snapshot_pattern1_${workspace.current_user.id}"
      development: true
      continuous: false
      channel: "CURRENT"
      photon: false
      libraries:
        - notebook:
            path: ./src/notebooks/process_snapshot_pattern1.py
        - notebook:
            path: ./src/notebooks/order_count_by_status_pattern1.sql   
      edition: "ADVANCED"
      permissions:
            - level: CAN_VIEW
              group_name: users
      clusters:
        - label: "default"
          autoscale:
            min_workers": 1,
            max_workers": 5,
            mode": "ENHANCED"
            # num_workers: 1
      configuration:
        snapshot_source_database: ${workspace.current_user.id}_snapshots   

    dlt_snapshot_ingestion_pattern2:
      name: "DLT Apply Changes from Snapshot - Pattern2 [${workspace.current_user.id}]"
      target: "snapshot_pattern2_${workspace.current_user.id}"
      development: true
      continuous: false
      channel: "CURRENT"
      photon: false
      libraries:
        - notebook:
            path: ./src/notebooks/process_snapshot_pattern2.py
        - notebook:
            path: ./src/notebooks/order_count_by_status_pattern2.sql   
      edition: "ADVANCED"
      permissions:
            - level: CAN_VIEW
              group_name: users
      clusters:
        - label: "default"
          aws_attributes: 
            instance_profile_arn: ${var.my_instance_profile_arn}
          autoscale:
            min_workers": 1,
            max_workers": 5,
            mode: "ENHANCED"
            # num_workers: 1
      configuration:
        snapshot_root_path: ${var.my_s3_bucket}/snapshot_ingestion_demo/orders/snapshots_${workspace.current_user.id}

  jobs:
    dlt_snapshot_ingestion_pattern1_job:
      name: "DLT Snapshot Ingestion - Pattern1 [${workspace.current_user.id}]"
      permissions:
        - level: CAN_VIEW
          group_name: users
      job_clusters: 
        - job_cluster_key: job_cluster
          new_cluster:
                spark_version: 12.2.x-scala2.12
                node_type_id: i3.xlarge
                num_workers: 1
      tasks:
        - task_key: generate_orders_snapshot
          job_cluster_key: job_cluster
          notebook_task:
            notebook_path: ./src/notebooks/generate_snapshot.py
            base_parameters:
              snapshot_pattern: "Pattern 1"
              snapshot_source_database: ${workspace.current_user.id}_snapshots
              num_orders: ${var.num_orders}
          libraries:
            - pypi:
                package: Faker==19.6.2
        - task_key: cdc_from_snapshot
          depends_on: [{
                        "task_key": "generate_orders_snapshot"
                    }]
          run_if: ALL_SUCCESS
          pipeline_task:
            pipeline_id: ${resources.pipelines.dlt_snapshot_ingestion_pattern1.id}
            full_refresh: false

    dlt_snapshot_ingestion_pattern2_job:
      name: "DLT Snapshot Ingestion - Pattern2 [${workspace.current_user.id}]"
      permissions:
        - level: CAN_VIEW
          group_name: users
      job_clusters: 
        - job_cluster_key: job_cluster
          new_cluster:
                spark_version: 12.2.x-scala2.12
                node_type_id: i3.xlarge
                num_workers: 1
                aws_attributes:
                  instance_profile_arn: ${var.my_instance_profile_arn}
      tasks:
        - task_key: generate_orders_snapshot
          job_cluster_key: job_cluster
          notebook_task:
            notebook_path: ./src/notebooks/generate_snapshot.py
            base_parameters:
              snapshot_pattern: "Pattern 2"
              snapshot_source_path: ${var.my_s3_bucket}/snapshot_ingestion_demo/orders/snapshots_${workspace.current_user.id}
              num_orders: ${var.num_orders}
          libraries:
            - pypi:
                package: Faker==19.6.2
        - task_key: cdc_from_snapshot
          depends_on: [{
                        "task_key": "generate_orders_snapshot"
                    }]
          run_if: ALL_SUCCESS
          pipeline_task:
            pipeline_id: ${resources.pipelines.dlt_snapshot_ingestion_pattern2.id}
            full_refresh: false


targets:
  development:
    workspace:
      default: true